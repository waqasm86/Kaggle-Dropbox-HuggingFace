{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip -q install -U  tqdm requests transformers accelerate bitsandbytes sentencepiece einops safetensors openai  huggingface_hub dropbox>/dev/null","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T14:33:41.137450Z","iopub.execute_input":"2025-08-19T14:33:41.137779Z","iopub.status.idle":"2025-08-19T14:33:46.368091Z","shell.execute_reply.started":"2025-08-19T14:33:41.137753Z","shell.execute_reply":"2025-08-19T14:33:46.367172Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import torch, os, json, pathlib, gc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T14:33:58.812951Z","iopub.execute_input":"2025-08-19T14:33:58.813280Z","iopub.status.idle":"2025-08-19T14:34:02.574701Z","shell.execute_reply.started":"2025-08-19T14:33:58.813253Z","shell.execute_reply":"2025-08-19T14:34:02.573331Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import os, json, pathlib, posixpath, re, sys, time\nfrom typing import Optional, Iterable\nimport dropbox\nfrom dropbox.exceptions import AuthError, ApiError\nfrom google.colab import userdata\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T14:34:02.576039Z","iopub.execute_input":"2025-08-19T14:34:02.576439Z","iopub.status.idle":"2025-08-19T14:34:02.779340Z","shell.execute_reply.started":"2025-08-19T14:34:02.576415Z","shell.execute_reply":"2025-08-19T14:34:02.778398Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import os\nHOME = os.getcwd()\nprint(HOME)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T14:34:38.738424Z","iopub.execute_input":"2025-08-19T14:34:38.738714Z","iopub.status.idle":"2025-08-19T14:34:38.744668Z","shell.execute_reply.started":"2025-08-19T14:34:38.738694Z","shell.execute_reply":"2025-08-19T14:34:38.742797Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nDBX_APP_KEY = UserSecretsClient().get_secret(\"DBX_APP_KEY\")\nDBX_APP_SECRET = UserSecretsClient().get_secret(\"DBX_APP_SECRET\") \nDBX_REFRESH_TOKEN = UserSecretsClient().get_secret(\"DBX_REFRESH_TOKEN\")\nHF_TOKEN = UserSecretsClient().get_secret(\"HF_TOKEN\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T14:43:27.088003Z","iopub.execute_input":"2025-08-19T14:43:27.088325Z","iopub.status.idle":"2025-08-19T14:43:27.720631Z","shell.execute_reply.started":"2025-08-19T14:43:27.088304Z","shell.execute_reply":"2025-08-19T14:43:27.719523Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import pathlib\n\nDBX_MODEL_DIR   = \"/p1-gemma-3-1b-it\"                # Dropbox folder path\nLOCAL_MODEL_DIR = \"/kaggle/working/gemma-3-1b-it\"    # Kaggle temp storage\n\n# Create the local directory if it doesn’t exist\npathlib.Path(LOCAL_MODEL_DIR).mkdir(parents=True, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T14:45:55.756230Z","iopub.execute_input":"2025-08-19T14:45:55.756673Z","iopub.status.idle":"2025-08-19T14:45:55.766750Z","shell.execute_reply.started":"2025-08-19T14:45:55.756645Z","shell.execute_reply":"2025-08-19T14:45:55.765269Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from huggingface_hub import login\n\nlogin(token=HF_TOKEN)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T14:44:24.816162Z","iopub.execute_input":"2025-08-19T14:44:24.816467Z","iopub.status.idle":"2025-08-19T14:44:25.452691Z","shell.execute_reply.started":"2025-08-19T14:44:24.816449Z","shell.execute_reply":"2025-08-19T14:44:25.451703Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"!pwd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T14:46:01.394198Z","iopub.execute_input":"2025-08-19T14:46:01.394496Z","iopub.status.idle":"2025-08-19T14:46:01.530183Z","shell.execute_reply.started":"2025-08-19T14:46:01.394476Z","shell.execute_reply":"2025-08-19T14:46:01.529059Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Use a pipeline as a high-level helper\nfrom transformers import pipeline\n\npipe = pipeline(\"text-generation\", model=\"google/gemma-3-1b-it\")\nmessages = [\n    {\"role\": \"user\", \"content\": \"Who are you?\"},\n]\npipe(messages)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T14:46:47.110728Z","iopub.execute_input":"2025-08-19T14:46:47.111102Z","iopub.status.idle":"2025-08-19T14:47:49.462812Z","shell.execute_reply.started":"2025-08-19T14:46:47.111074Z","shell.execute_reply":"2025-08-19T14:47:49.462068Z"}},"outputs":[{"name":"stderr","text":"2025-08-19 14:46:55.087595: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1755614815.412331      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1755614815.503037      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/899 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"913362c7a89241a0a5f37ec0f954254d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4182c163d01045ccaa5f7475f8a61270"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/215 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9784fdf9eb6e4e38870774565ee33ef9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82ca944d30d14d01885735a69a94af50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77a3e9b1461e4fa2a515771417ae75e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50e2575001804019a016a472ded637b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd4a16ac57c642769b7d461f9d02e0ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fe61479a99240ceae57a730dded8ca2"}},"metadata":{}},{"name":"stderr","text":"Device set to use cpu\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"[{'generated_text': [{'role': 'user', 'content': 'Who are you?'},\n   {'role': 'assistant',\n    'content': 'Hi there! I’m Gemma, a large language model created by the Gemma team at Google DeepMind. I’m an open-weights model, which means I’m publicly available for anyone to use! \\n\\nI’m designed to take text and images as input and produce text as output. \\n\\nHow can I help you today?'}]}]"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"# Load model directly\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"google/gemma-3-1b-it\")\nmodel = AutoModelForCausalLM.from_pretrained(\"google/gemma-3-1b-it\")\nmessages = [\n    {\"role\": \"user\", \"content\": \"Who are you?\"},\n]\ninputs = tokenizer.apply_chat_template(\n\tmessages,\n\tadd_generation_prompt=True,\n\ttokenize=True,\n\treturn_dict=True,\n\treturn_tensors=\"pt\",\n).to(model.device)\n\noutputs = model.generate(**inputs, max_new_tokens=40)\nprint(tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T14:48:12.940945Z","iopub.execute_input":"2025-08-19T14:48:12.941599Z","iopub.status.idle":"2025-08-19T14:48:32.094857Z","shell.execute_reply.started":"2025-08-19T14:48:12.941578Z","shell.execute_reply":"2025-08-19T14:48:32.093523Z"}},"outputs":[{"name":"stdout","text":"Hi there! I’m Gemma, a large language model created by the Gemma team at Google DeepMind. I’m an open-weights model, which means I’m publicly available for anyone\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}