{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1iuM2envTqTTTZdGzwYtq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waqasm86/Kaggle-Dropbox-HuggingFace/blob/main/p3_colab_dropbox_huggingface.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mp2XYhc1j-ni",
        "outputId": "2e4d16fe-7aa1-4e8c-a328-86d46b770511"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip -q install -U huggingface_hub dropbox requests > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -U  tqdm requests transformers accelerate bitsandbytes sentencepiece einops safetensors openai >/dev/null"
      ],
      "metadata": {
        "id": "Cz-z99DskKbs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, os, json, pathlib, gc"
      ],
      "metadata": {
        "id": "xfoII_xgkLk5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, pathlib, posixpath, re, sys, time\n",
        "from typing import Optional, Iterable\n",
        "import dropbox\n",
        "from dropbox.exceptions import AuthError, ApiError"
      ],
      "metadata": {
        "id": "85g8FbQIkOQ5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, pathlib\n",
        "from google.colab import userdata\n",
        "\n",
        "# ---- Dropbox (preferred: offline/refreshable) ----\n",
        "os.environ[\"DBX_APP_KEY\"]       = userdata.get('DBX_APP_KEY')\n",
        "os.environ[\"DBX_APP_SECRET\"]    = userdata.get('DBX_APP_SECRET')\n",
        "os.environ[\"DBX_REFRESH_TOKEN\"] = userdata.get('DBX_REFRESH_TOKEN')\n",
        "os.environ[\"HF_TOKEN\"] = userdata.get('HF_TOKEN')\n",
        "\n",
        "DBX_MODEL_DIR  = \"/p1-gemma-3-1b-it\"         # your Dropbox folder from Kaggle step\n",
        "LOCAL_MODEL_DIR = \"/content/gemma-3-1b-it\"   # Colab temp storage\n",
        "pathlib.Path(LOCAL_MODEL_DIR).mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "_y3TiOV1kPbk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a pipeline as a high-level helper\n",
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=\"google/gemma-3-1b-it\")\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
        "]\n",
        "pipe(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392,
          "referenced_widgets": [
            "f90d1b35c99b49a4b554d5282c29ca52",
            "026f030ac3de4368bdc14feff795fa02",
            "f3ad9403b9e849a2a488055a3dcfc9ad",
            "ebc67b3d2fd04b1b9d18da1c647f7124",
            "5071b9ed12134437827685503d6bac1e",
            "133a008e6e5842b19d3ccc56ea4497a9",
            "f9e96648ca34440ab8e4afbfd672c0be",
            "ed4af7e2849e49cfb148962814b3f21d",
            "4440663075754a0f8b8d18d206ef2cef",
            "a14e0b3728414a8b835611b1db1207c7",
            "04704e22687f432c89775be7d3ef378e",
            "96cc57186a0f48a2a3a144164dd427e1",
            "6028fb9639d143a39b21703dbcaedbd1",
            "e8e150bdaeb24857925b83fced73f2ae",
            "c95faa6df0e44e8c9a214d080c997c7f",
            "05e9a0eba1db45aba645dbb36db37c2a",
            "5b716f56f2c748f1900558a3e0a2a60f",
            "65efa98e827049f6845273ae5c072899",
            "c5949953f11c4803a30bf9486a0f577e",
            "27ff2961da574bb98b4089e307f37510",
            "ccb0c0463d1346599e8dcdfa635b8434",
            "6a56ffc908d8441da86a054b851a9ad3",
            "dba135d94a644c7f87590363b7265994",
            "507b204ed6834197bd18c205f64c7c18",
            "e3d1028f1b104eaba85517b751d2acab",
            "bc34864f56e54d5a87aab9167168c621",
            "5f681f6dc6e74ece82fe22838370a6e9",
            "76eb4423bdd74b888a35294be9eee480",
            "419d66cc112e4262a30e1b93a8c5c629",
            "9d285f2bbf364852be7e28362f66da06",
            "d534f44e2c31403bafd8ed8737e49349",
            "a164e11176994306907ec4e491e95d3f",
            "71169af14a8140e5859753fa35dac18f",
            "cf98520713304b9c9a2252b2114541d5",
            "29472e9e934d4ce38d416ed8cce76f39",
            "903c8c6b5c4f43c682a6c187af176c05",
            "e44bb4b56f974146966c74e3423766bf",
            "be75676c473c433ab34d40b8d691e6d1",
            "53fbdc47b5744a2c91a1fe5e650cb122",
            "f4ef008b0e0745a19ee5b312b91bc55c",
            "273282c53fc54701b409cfcb7c2b0603",
            "a0ec7bd93abb4910b491304505fd2d3f",
            "16ffa8f77a89402a9d31e3d9d61b4616",
            "e04d54e9a1244e8b9618ba700d978f7d",
            "251b337915ab4ff39f04cf6619cc695c",
            "909a66255a6544a9ac634cccf84623e2",
            "a654c651a7c94d9f8155ac2606c35ee9",
            "a6fc3c6efd1046d0b8bc92b2f89a3612",
            "b8ade18073f5414786f19ab05a035926",
            "7fd4c8c43977445085c864164dfcb012",
            "2fb6f9e53ae043e3b10f30b575e3cfe1",
            "b36727f33c074de9859908d0eecb7995",
            "fd0c187785544d1db66d99eaf8f69bee",
            "25a986ab63084fd89df1caea17aecef6",
            "f1c963590c77455484c579e57ce6f2b6",
            "05f0c366008f44afb7c22bd8f71a86d7",
            "e016f111e2dd48dda814182bd9e8238e",
            "37cc25d434434414b7d425faec987753",
            "4fd8a89892724a2b9a7d07dd839a869b",
            "74cd60c8fed145b99cfbcda15386447f",
            "7d30073b2e8446979205d161cbdf3b92",
            "12c4127f89654a92aa381a39ca3729b1",
            "0ed5632ab7594802b3fb67e0202efbd8",
            "3b020b424ef3474cb572f7466dca5eb6",
            "70908005cbb14174ba28646df8ee2b14",
            "9faf5d38604d4facba5fbcb2eefec94b",
            "0d8bbf35f1f94d61b3d2a24450f528a6",
            "51eb83d9620e48dd91564dcb84fccf90",
            "6684d39e4ce641ac87f6aba258b5103b",
            "bd104ce9c8574c7e9d5228ce2508e612",
            "354e43b2b6124e26a911ddc32c30cfc7",
            "492e145376c14dbab3741bba84ccc5b1",
            "7a19619c953d4086863d2222f9646152",
            "9551a4ab720a4c078d23d58ca0c752da",
            "af41a3605e7b41cc96655835150be740",
            "07782f55f5ea43d5996e8cad52849c66",
            "711553bbb2ea41bf9dbd9c30112c99d2",
            "720c7ed9426847dfa69157dc31fd51f4",
            "42695a27919c4fdcb9944737679bf601",
            "b223a5441e7d4753914b5a4995e34413",
            "9d689a4f733f41fb97fc566a282a8aeb",
            "1b82855f9d304a4daf38b236425cac7f",
            "c8877323cf02496292ac60e6a7a389e5",
            "650cc71914f043d2bf98634abe9c98d5",
            "1a606b83e11c4da7a788b724dc7af36b",
            "40606aa619704b77aaebe282731f8352",
            "53444d72ddba48e8a3505d6c994d91f5",
            "115bcd53c6a643709da85ceeecff1704"
          ]
        },
        "id": "_NdrQUnmkaw0",
        "outputId": "8818576b-9f29-48cc-84f7-aa1c2727647c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/899 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f90d1b35c99b49a4b554d5282c29ca52"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96cc57186a0f48a2a3a144164dd427e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/215 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dba135d94a644c7f87590363b7265994"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf98520713304b9c9a2252b2114541d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "251b337915ab4ff39f04cf6619cc695c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05f0c366008f44afb7c22bd8f71a86d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d8bbf35f1f94d61b3d2a24450f528a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "720c7ed9426847dfa69157dc31fd51f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': [{'role': 'user', 'content': 'Who are you?'},\n",
              "   {'role': 'assistant',\n",
              "    'content': 'Hi there! I’m Gemma, a large language model created by the Gemma team at Google DeepMind. I’m an open-weights model, which means I’m publicly available for anyone to use! \\n\\nI’m designed to take text and images as input and produce text as output. \\n\\nHow can I help you today?'}]}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-3-1b-it\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-3-1b-it\")\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "\tmessages,\n",
        "\tadd_generation_prompt=True,\n",
        "\ttokenize=True,\n",
        "\treturn_dict=True,\n",
        "\treturn_tensors=\"pt\",\n",
        ").to(model.device)\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens=40)\n",
        "print(tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FQ8sauDkj5U",
        "outputId": "bb68d070-1a6c-46e2-990e-56e47e873b9a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi there! I’m Gemma, a large language model created by the Gemma team at Google DeepMind. I’m an open-weights model, which means I’m publicly available for anyone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S255yNBxma7f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
